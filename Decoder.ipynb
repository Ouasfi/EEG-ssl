{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from '/home/brain/EEG-ssl/dataset.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from settings  import *\n",
    "from preprocessing import *\n",
    "import mne\n",
    "import dataset as ds\n",
    "from train import *\n",
    "import decode as dec\n",
    "from importlib import reload\n",
    "\n",
    "from models import Relative_Positioning, StagerNet, Decoder\n",
    "from dataset import Decoder_Dataset, DecoderSampler, SequentialSampler\n",
    "import process\n",
    "from train import load_losses, save_losses\n",
    "from torch import nn, optim\n",
    "import argparse \n",
    "reload(process)\n",
    "reload(dec)\n",
    "reload(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models params\n",
    "C = 64\n",
    "T =1000\n",
    "M = 600\n",
    "#training paramms\n",
    "epochs = 20\n",
    "batch_size = 40\n",
    "lr = 1e-3\n",
    "resume = False\n",
    "#datasets params\n",
    "n_train = 22000\n",
    "n_test = 3000\n",
    "#sampling params\n",
    "pos= 4000\n",
    "neg = 8000\n",
    "\n",
    "s_weights = [0.5, 1-0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import *\n",
    "from pylab import *\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch.nn.functional import soft_margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os\n",
    "from settings  import *\n",
    "from preprocessing import *\n",
    "from models import Relative_Positioning, StagerNet, Decoder\n",
    "from dataset import Decoder_Dataset, DecoderSampler, collate\n",
    "import process\n",
    "from train import load_losses, save_losses\n",
    "from torch import nn, optim\n",
    "import argparse \n",
    "from get_results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = SUBJECTS[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_model = Relative_Positioning(StagerNet,C , T, embedding_dim = M )\n",
    "model = ssl_model.feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, EEG_FeatureExtractor, aggregator,  C, T, embedding_dim=100, hidden_dim= 20):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = EEG_FeatureExtractor\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.C = C\n",
    "        self.T = T\n",
    "        #self.feature_extractor.float()\n",
    "        self.linear1 = nn.Linear(embedding_dim//2, 12)\n",
    "        self.aggr = nn.AdaptiveAvgPool2d((1,300))\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[1]#pad\n",
    "        x = x.reshape(-1, 1, self.C, self.T)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.reshape(-1, batch,self.embedding_dim ).permute(1,0,2)\n",
    "        x = self.aggr(x)\n",
    "        x= self.flatten(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        return x.squeeze(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy(nn.Module):\n",
    "    \n",
    "    def __init__(self ):\n",
    "        super().__init__()\n",
    "        #self.feature_extractor = EEG_FeatureExtractor\n",
    "        #self.feature_extractor.float()\n",
    "        self.aggr = nn.AdaptiveAvgPool3d((1,5,1000))\n",
    "        self.linear1 = nn.Linear(5000, 12)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = self.flatten(x.unsqueeze(dim = 0))\n",
    "        x = self.aggr (x.permute(1,0,2,3))\n",
    "        x= self.flatten(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        print(x.shape)\n",
    "        return x.squeeze(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ssl_model = Relative_Positioning(StagerNet,C , T, embedding_dim = M )\n",
    "#ssl_model.load_state_dict(torch.load(os.path.join(ROOT, 'saved_models', 'ssl_model_epoch40.pt')))\n",
    "#model = ssl_model.feature_extractor\n",
    "#subjects = SUBJECTS[:-2]\n",
    "#val_subjects = [SUBJECTS[-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dummy(\n",
       "  (aggr): AdaptiveAvgPool3d(output_size=(1, 5, 1000))\n",
       "  (linear1): Linear(in_features=5000, out_features=12, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (flatten): Flatten()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoder =Dummy()\n",
    "#decoder.to(float).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(model, 0, C, T, embedding_dim=M, hidden_dim = 20)\n",
    "decoder.to(DEVICE).float();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate(batch):\n",
    "   \n",
    "    samples= pad_sequence([item[0] for item in batch])\n",
    "    targets =torch.tensor( [item[1] for item in batch])\n",
    "    \n",
    "    return samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_results(model, test_loader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for x, y in test_loader:\n",
    "            \n",
    "            x = x.to(DEVICE).to(float).contiguous().squeeze(dim= 2)\n",
    "            y = y.to(DEVICE).to(float).contiguous()\n",
    "            out = model(x)\n",
    "            _, predicted = torch.max(softmax(out), 1)\n",
    "            y_true.extend(list(y.cpu().numpy()))\n",
    "            y_pred.extend(list(predicted.cpu().numpy()))\n",
    "    return y_true, y_pred\n",
    "\n",
    "def decoder_scores(model, subjects, trials):\n",
    "    \n",
    "    test_dataset = Decoder_Dataset(subjects,trials, T, step = 512)\n",
    "    test_sampler = SequentialSampler(test_dataset, batch_size = 168, weights = [1/12]*12, size = 168)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, num_workers=0,\n",
    "                                          sampler = test_sampler)\n",
    "    y_true, y_pred = get_test_results(model, test_loader)\n",
    "    acc_score = accuracy_score(y_true, y_pred)\n",
    "    balanced_acc_score = balanced_accuracy_score(y_true, y_pred)\n",
    "    print(f'Performance of the network on the test trials:')\n",
    "    print(f'\\tAccuracy: {100*acc_score:.2f}%')\n",
    "    print(f'\\tBalanced accuracy: {100*balanced_acc_score:.2f}%')\n",
    "    return acc_score, balanced_acc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "softmax = nn.Softmax(dim = 1)\n",
    "def _train_dec(model, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for x, y in train_loader:\n",
    "        x = x.squeeze(dim = 2).to(DEVICE).float()\n",
    "        y = y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        loss = model.loss_fn(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scores\n",
    "        _, predicted = torch.max(softmax(out), 1)\n",
    "        y_true.extend(list(y.cpu().numpy()))\n",
    "        y_pred.extend(list(predicted.cpu().numpy()))\n",
    "        train_losses.append(loss.item())\n",
    "    acc_score = accuracy_score(y_true, y_pred)\n",
    "    return np.mean(train_losses), acc_score\n",
    "def _eval_loss_dec(model, data_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            #print(x.shape)\n",
    "            x = x.squeeze(dim= 2 ).to(DEVICE).float()\n",
    "            y = y.to(DEVICE)\n",
    "            out = model(x)\n",
    "            loss = model.loss_fn(out, y)\n",
    "            _, predicted = torch.max(softmax(out), 1)\n",
    "            y_true.extend(list(y.cpu().numpy()))\n",
    "            y_pred.extend(list(predicted.cpu().numpy()))\n",
    "            losses.append(loss.item())\n",
    "        acc_score = accuracy_score(y_true, y_pred)\n",
    "    return np.mean(losses), acc_score\n",
    "\n",
    "def _train_epochs_dec(model, train_loader, test_loader, train_args):\n",
    "    \n",
    "    epochs, lr = train_args['epochs'], train_args['lr']\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay = 1e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer,step_size = 20, gamma = 0.001)\n",
    "    if not os.path.exists(SAVED_MODEL_DIR):\n",
    "        os.makedirs(SAVED_MODEL_DIR)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = [_eval_loss_dec(model, test_loader)]\n",
    "    accs = {\"train\":[],\"val\":[]}\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss, train_acc = _train_dec(model, train_loader, optimizer, epoch)\n",
    "        accs['train'].append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        test_loss, val_acc = _eval_loss_dec(model, test_loader)\n",
    "        accs['val'].append(val_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch}, Train loss {train_loss:.4f},Val loss {test_loss:.4f}, \\tTrain Accuracy: {100*train_acc:.2f}%,, \\tVal Accuracy: {100*val_acc:.2f}%')\n",
    "\n",
    "        # save model every 10 epochs\n",
    "        if epoch % 2 == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(ROOT, 'saved_models', 'decoder_epoch{}.pt'.format(epoch)))\n",
    "    torch.save(model.state_dict(), os.path.join(ROOT, 'saved_models', 'decoder.pt'))\n",
    "    return train_losses, test_losses, accs\n",
    "\n",
    "\n",
    "\n",
    "def train_decoder(model, train_dataset, val_dataset,samplers, n_epochs=20, lr=1e-3, batch_size=256, load_last_saved_model=False, num_workers=8):\n",
    "\t\n",
    "\tif load_last_saved_model:\n",
    "\t\tmodel.load_state_dict(torch.load(os.path.join(ROOT, SAVED_MODEL_DIR, 'decoder.pt')))\n",
    "\tif torch.cuda.device_count() > 1:\n",
    "\t\tmodel = nn.DataParallel(model)\n",
    "\tmodel.to(DEVICE)\n",
    "\n",
    "\ttrain_loader =  torch.utils.data.DataLoader(train_dataset,batch_size = batch_size, num_workers=0,\n",
    "                                          sampler = samplers[\"train\"], collate_fn = collate)\n",
    "\tval_loader = torch.utils.data.DataLoader(val_dataset, num_workers=0,\n",
    "                                          sampler = samplers[\"val\"], batch_size = 40, collate_fn = collate)\n",
    "\tnew_train_losses, new_test_losses, accs = _train_epochs_dec(model, train_loader, val_loader, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t dict(epochs=n_epochs, lr=lr))\n",
    "\tif load_last_saved_model:\n",
    "\t\ttrain_losses, test_losses = load_losses(SAVED_MODEL_DIR, 'decoder')\n",
    "\telse:\n",
    "\t\ttrain_losses = []\n",
    "\t\ttest_losses = []\n",
    "\ttrain_losses.extend(new_train_losses)\n",
    "\ttest_losses.extend(new_test_losses)\n",
    "\tsave_losses(train_losses, test_losses, SAVED_MODEL_DIR, 'decoder')\n",
    "\treturn train_losses, test_losses, accs, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 15 18:36:26 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.88       Driver Version: 418.88       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 106...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   42C    P8     8W / 200W |   3862MiB /  6076MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1033      G   /usr/lib/xorg/Xorg                            14MiB |\r\n",
      "|    0      1090      G   /usr/bin/gnome-shell                          20MiB |\r\n",
      "|    0      1558      G   /usr/lib/xorg/Xorg                            59MiB |\r\n",
      "|    0      1706      G   /usr/bin/gnome-shell                         104MiB |\r\n",
      "|    0     21811      C   /usr/bin/python3                            3651MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Decoder_Dataset(subjects,[0,1,3,4], T, step = 512)\n",
    "val_dataset = Decoder_Dataset(subjects,[2], T, step = 512)\n",
    "train_sampler = DecoderSampler(train_dataset, batch_size = 40, weights = [1/12]*12, size = 400)\n",
    "val_sampler = SequentialSampler(val_dataset, batch_size = 40, weights = [1/12]*12, size = 168)\n",
    "samplers = {\"train\" : train_sampler, \"val\": val_sampler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.60 GiB (GPU 0; 5.93 GiB total capacity; 2.93 GiB already allocated; 2.16 GiB free; 3.10 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-35a4d4e4ee0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m a = train_decoder(decoder, train_dataset, val_dataset,samplers, n_epochs=15, lr=1e-3,\n\u001b[0;32m----> 4\u001b[0;31m                   batch_size=40, num_workers=0)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-6c89f404d204>\u001b[0m in \u001b[0;36mtrain_decoder\u001b[0;34m(model, train_dataset, val_dataset, samplers, n_epochs, lr, batch_size, load_last_saved_model, num_workers)\u001b[0m\n\u001b[1;32m     85\u001b[0m                                           sampler = samplers[\"val\"], batch_size = 40, collate_fn = collate)\n\u001b[1;32m     86\u001b[0m \tnew_train_losses, new_test_losses, accs = _train_epochs_dec(model, train_loader, val_loader, \n\u001b[0;32m---> 87\u001b[0;31m \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t dict(epochs=n_epochs, lr=lr))\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_last_saved_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVED_MODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-6c89f404d204>\u001b[0m in \u001b[0;36m_train_epochs_dec\u001b[0;34m(model, train_loader, test_loader, train_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_eval_loss_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-6c89f404d204>\u001b[0m in \u001b[0;36m_eval_loss_dec\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-130cc0cf8c3c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#pad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EEG-ssl/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp_conv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0;31m# a relu activation is used before batch_norm, is it the case in the original implementation ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.60 GiB (GPU 0; 5.93 GiB total capacity; 2.93 GiB already allocated; 2.16 GiB free; 3.10 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "\n",
    "import decode \n",
    "reload(decode)\n",
    "a = train_decoder(decoder, train_dataset, val_dataset,samplers, n_epochs=15, lr=1e-3,\n",
    "                  batch_size=40, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Self supervised StagerNet Losses')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from get_results import*\n",
    "from pylab import *\n",
    "train_losses, test_losses = load_losses(SAVED_MODEL_DIR, 'ssl')\n",
    "plot(train_losses)\n",
    "plot(test_losses)\n",
    "legend([\"train loss\", \"val loss\"])\n",
    "title(\"Self supervised StagerNet Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb05072d358>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0528817b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(train_losses)\n",
    "plot(test_losses)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "val_subject = SUBJECTS[-2]\n",
    "val_dataset =  ds.RP_Dataset([val_subject], sampling_params = (pos, neg), temp_len = T ,\n",
    "                                n_features = C )\n",
    "val_sampler = ds.WeightedSampler(val_dataset, batch_size = batch_size ,size = 3000,  \n",
    "                              weights = s_weights)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=0,sampler = val_sampler, collate_fn=ssl_collate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "losses = []\n",
    "for epoch in arange(4,50, 4):\n",
    "    ssl_model.load_state_dict(torch.load(os.path.join(ROOT, 'saved_models',\n",
    "                                                      f'ssl_model_epoch{epoch}.pt')))\n",
    "    ssl_model.to(DEVICE).double()\n",
    "    #model = ssl_model.feature_extractor\n",
    "    loss = _eval_loss(ssl_model, val_loader)\n",
    "    print(loss)\n",
    "    losses.append(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
