{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from '/home/brain/EEG-ssl/dataset.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from settings  import *\n",
    "from preprocessing import *\n",
    "import mne\n",
    "import dataset as ds\n",
    "from train import *\n",
    "import decode as dec\n",
    "from importlib import reload\n",
    "\n",
    "from models import Relative_Positioning, StagerNet, Decoder\n",
    "from dataset import Decoder_Dataset, DecoderSampler, SequentialSampler\n",
    "import process\n",
    "from train import load_losses, save_losses\n",
    "from torch import nn, optim\n",
    "import argparse \n",
    "reload(process)\n",
    "reload(dec)\n",
    "reload(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models params\n",
    "C = 64\n",
    "T =1000\n",
    "M = 10\n",
    "#training paramms\n",
    "epochs = 20\n",
    "batch_size = 40\n",
    "lr = 1e-3\n",
    "resume = False\n",
    "#datasets params\n",
    "n_train = 4000\n",
    "n_test = 500\n",
    "#sampling params\n",
    "pos= 3000\n",
    "neg = 7000\n",
    "\n",
    "s_weights = [0.5, 1-0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import *\n",
    "from pylab import *\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch.nn.functional import soft_margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import sys\n",
    "\n",
    "class DummyFile(object):\n",
    "    def write(self, x): pass\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def nostdout():\n",
    "    save_stdout = sys.stdout\n",
    "    sys.stdout = DummyFile()\n",
    "    yield\n",
    "    sys.stdout = save_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _train_dec(model, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    batch_size = train_loader.batch_size\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        #print(batch_y)\n",
    "        #print('in')\n",
    "        loss = torch.tensor([0.0], requires_grad=True)\n",
    "        for x,y in zip(batch_x, batch_y):\n",
    "            x = x.squeeze(dim= 0 )\n",
    "            y = y.to(DEVICE)\n",
    "            out = model(x)\n",
    "            #print(out.shape)\n",
    "            loss = loss+ model.loss_fn(out.unsqueeze(dim =0), y)\n",
    "        loss =loss/batch_size\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    return [mean(train_losses)]\n",
    "def _eval_loss_dec(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.squeeze(dim= 0 )\n",
    "            y = y.to(DEVICE)\n",
    "            loss = model.loss_fn(model(x).unsqueeze(dim = 0), y)\n",
    "            total_loss += loss #* x[0].shape[0] #\n",
    "        avg_loss = total_loss / data_loader.sampler.size# / len(data_loader.dataset)\n",
    "    return avg_loss.item()\n",
    "\n",
    "def _train_epochs_dec(model, train_loader, test_loader, train_args):\n",
    "    \n",
    "    epochs, lr = train_args['epochs'], train_args['lr']\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    if not os.path.exists(SAVED_MODEL_DIR):\n",
    "        os.makedirs(SAVED_MODEL_DIR)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = [_eval_loss_dec(model, test_loader)]\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_losses.extend(_train_dec(model, train_loader, optimizer, epoch))\n",
    "        test_loss = _eval_loss_dec(model, test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        y_true, y_pred = get_test_results(model, test_loader)\n",
    "        acc_score = accuracy_score(y_true, y_pred)\n",
    "        print(f'Epoch {epoch}, Test loss {test_loss:.4f}, \\tAccuracy: {100*acc_score:.2f}%')\n",
    "\n",
    "        # save model every 10 epochs\n",
    "        if epoch % 2 == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(ROOT, 'saved_models', 'decoder_epoch{}.pt'.format(epoch)))\n",
    "    torch.save(model.state_dict(), os.path.join(ROOT, 'saved_models', 'decoder.pt'))\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "\n",
    "def train_decoder(model, train_dataset, val_dataset,samplers, n_epochs=20, lr=1e-3, batch_size=256, load_last_saved_model=False, num_workers=8):\n",
    "\t\n",
    "\tif load_last_saved_model:\n",
    "\t\tmodel.load_state_dict(torch.load(os.path.join(ROOT, SAVED_MODEL_DIR, 'decoder.pt')))\n",
    "\tif torch.cuda.device_count() > 1:\n",
    "\t\tmodel = nn.DataParallel(model)\n",
    "\tmodel.to(DEVICE)\n",
    "\n",
    "\ttrain_loader = train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size, num_workers=0,\n",
    "                                          sampler = samplers[\"train\"], collate_fn = collate)\n",
    "\tval_loader = val_loader = torch.utils.data.DataLoader(val_dataset, num_workers=0,\n",
    "                                          sampler = samplers[\"val\"])\n",
    "\tnew_train_losses, new_test_losses = _train_epochs_dec(model, train_loader, val_loader, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t dict(epochs=n_epochs, lr=lr))\n",
    "\tif load_last_saved_model:\n",
    "\t\ttrain_losses, test_losses = load_losses(SAVED_MODEL_DIR, 'decoder')\n",
    "\telse:\n",
    "\t\ttrain_losses = []\n",
    "\t\ttest_losses = []\n",
    "\ttrain_losses.extend(new_train_losses)\n",
    "\ttest_losses.extend(new_test_losses)\n",
    "\tsave_losses(train_losses, test_losses, SAVED_MODEL_DIR, 'decoder')\n",
    "\treturn train_losses, test_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, EEG_FeatureExtractor, aggregator,  C, T, embedding_dim=100, hidden_dim= 20):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = EEG_FeatureExtractor\n",
    "        #self.feature_extractor.float()\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, 12)\n",
    "        self.aggr = aggregator\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        out = self.aggr(x, axis = 0)\n",
    "        return out   \n",
    "    \n",
    "\n",
    "class AudioTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "     DETR implementation.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, hidden_dim=256, nheads=8,\n",
    "                 num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # create ResNet-50 backbone\n",
    "        \n",
    "        # create conversion layer\n",
    "        self.conv = nn.Conv2d(1024, hidden_dim, 1)\n",
    "\n",
    "        # create a default PyTorch transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "        # prediction heads, one extra class for predicting non-empty slots\n",
    "        # note that in baseline DETR linear_bbox layer is 3-layer MLP\n",
    "        self.linear_class = nn.Linear(hidden_dim, num_classes )\n",
    "        #self.linear_bbox = nn.Linear(hidden_dim, 4)\n",
    "\n",
    "        # output positional encodings (object queries)\n",
    "        self.query_pos = nn.Parameter(torch.rand(1, hidden_dim))\n",
    "\n",
    "        # spatial positional encodings\n",
    "        # note that in baseline DETR we use sine positional encodings\n",
    "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "        self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # convert from 2048 to 256 feature planes for the transformer\n",
    "        h = self.conv(inputs)\n",
    "        #print(h.shape)\n",
    "        # construct positional encodings\n",
    "        H, W = h.shape[-2:]\n",
    "        N = h.shape[0]\n",
    "        #print(H,W)\n",
    "        pos = torch.cat([\n",
    "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
    "        #print(h.flatten(1).shape)\n",
    "        #print(pos.shape)\n",
    "        e = pos + 0.1 * h.flatten(2).permute(2, 0, 1)\n",
    "        k = self.query_pos.unsqueeze(1).repeat(1,N,1)\n",
    "        #print(k.size(1), e.size(1))\n",
    "        #print(k.shape, e.shape)\n",
    "        # propagate through the transformer\n",
    "        h = self.transformer(pos + 0.1 * h.flatten(2).permute(2, 0, 1),\n",
    "                             self.query_pos.unsqueeze(1).repeat(1,N,1)).transpose(0, 1)\n",
    "        \n",
    "        # finally project transformer outputs to class labels and bounding boxes\n",
    "        return  torch.nn.Softmax(dim = 2)(self.linear_class(h) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transcoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,  C, T, nhead = 8, num_layers = 6,  hidden_dim= 20):\n",
    "        super().__init__()\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=1000, nhead=nhead)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        self.query = nn.Parameter(torch.rand(64, 1000).unsqueeze(0))\n",
    "\n",
    "        self.pooling = nn.AdaptiveMaxPool3d(output_size=( 10, 20))\n",
    "        self.linear2 = nn.Linear(200, 12)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = self.transformer_decoder(x, self.query)\n",
    "        print(x.shape)\n",
    "        x = self.pooling(x)\n",
    "        x = x.tanh()\n",
    "        x = self.flatten()\n",
    "        x = self.linear1(x)\n",
    "    \n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,14, 64,1000).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transcoder(\n",
       "  (decoder_layer): TransformerDecoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    )\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    (dropout3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "        (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooling): AdaptiveMaxPool3d(output_size=(10, 20))\n",
       "  (linear2): Linear(in_features=200, out_features=12, bias=True)\n",
       "  (flatten): Flatten()\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = Transcoder(C,T, 2, 4)\n",
    "cc.to(DEVICE).to(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #2 'mat2' in call to _th_mm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8738f3dc3b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-45813389e220>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    226\u001b[0m                                     \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                                     \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                                     memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[1;32m    350\u001b[0m         tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n\u001b[0;32m--> 351\u001b[0;31m                               key_padding_mask=tgt_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3222\u001b[0;31m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #2 'mat2' in call to _th_mm"
     ]
    }
   ],
   "source": [
    "cc(x.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dc708fb9c3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_test_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-7114da055356>\u001b[0m in \u001b[0;36mget_test_results\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b0baa70bfee5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    226\u001b[0m                                     \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                                     \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                                     memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[1;32m    350\u001b[0m         tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n\u001b[0;32m--> 351\u001b[0;31m                               key_padding_mask=tgt_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3209\u001b[0m     \"\"\"\n\u001b[1;32m   3210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m     \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0membed_dim_to_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "get_test_results(coder, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import get_results as res\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "def get_test_results(model, test_loader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for x, y in test_loader:\n",
    "            \n",
    "            x = x.to(DEVICE).to(float).contiguous().squeeze(dim= 0)\n",
    "            y = y.to(DEVICE).to(float).contiguous()\n",
    "            out = model(x)\n",
    "            _, predicted = torch.max(softmax(out.unsqueeze(dim =0)), 1)\n",
    "            y_true.extend(list(y.cpu().numpy()))\n",
    "            y_pred.extend(list(predicted.cpu().numpy()))\n",
    "    return y_true, y_pred\n",
    "\n",
    "def decoder_scores(model, subjects, trials):\n",
    "    \n",
    "    test_dataset = Decoder_Dataset(subjects,trials, T, step = 512)\n",
    "    test_sampler = SequentialSampler(test_dataset, batch_size = 168, weights = [1/12]*12, size = 168)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, num_workers=0,\n",
    "                                          sampler = test_sampler)\n",
    "    y_true, y_pred = get_test_results(model, test_loader)\n",
    "    acc_score = accuracy_score(y_true, y_pred)\n",
    "    balanced_acc_score = balanced_accuracy_score(y_true, y_pred)\n",
    "    print(f'Performance of the network on the test trials:')\n",
    "    print(f'\\tAccuracy: {100*acc_score:.2f}%')\n",
    "    print(f'\\tBalanced accuracy: {100*balanced_acc_score:.2f}%')\n",
    "    return acc_score, balanced_acc_score\n",
    "\n",
    "#decoder_scores(model_dec, subjects, [0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (feature_extractor): StagerNet(\n",
       "    (relu): ReLU()\n",
       "    (spatial_conv): Conv2d(1, 64, kernel_size=(64, 1), stride=(1, 1))\n",
       "    (temp_conv1): Conv2d(1, 16, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25))\n",
       "    (batch_norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (temp_conv2): Conv2d(16, 16, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25))\n",
       "    (batch_norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (maxPool): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
       "    (flatten): Flatten()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear_class): Linear(in_features=5120, out_features=10, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (linear2): Linear(in_features=20, out_features=12, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssl_model = Relative_Positioning(StagerNet,C , T, embedding_dim = M )\n",
    "ssl_model.load_state_dict(torch.load(os.path.join(ROOT, 'saved_models', 'ssl_model.pt')))\n",
    "model = ssl_model.feature_extractor\n",
    "subjects = SUBJECTS[:-2]\n",
    "    #split data\n",
    "val_subjects = [SUBJECTS[-2]]\n",
    "aggregator = torch.mean\n",
    "decoder = dec.Decoder(model, aggregator, C, T, embedding_dim=M, hidden_dim = 20)\n",
    "decoder.to(float).to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Decoder_Dataset(subjects,[0,1,3,4], T, step = 512)\n",
    "val_dataset = Decoder_Dataset(subjects,[2], T, step = 512)\n",
    "train_sampler = DecoderSampler(train_dataset, batch_size = 50, weights = [1/12]*12, size = 400)\n",
    "val_sampler = SequentialSampler(val_dataset, batch_size = 168, weights = [1/12]*12, size = 168)\n",
    "samplers = {\"train\" : train_sampler, \"val\": val_sampler}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = 50, num_workers=0,\n",
    "                                          sampler = samplers[\"train\"], collate_fn = collate)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, num_workers=0,\n",
    "                                          sampler = samplers[\"val\"])\n",
    "\n",
    "#train_losses, test_losses, model_dec = train_decoder(decoder, train_dataset, val_dataset,samplers, n_epochs=30, lr=1e-4, \n",
    "             # batch_size=50, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for x ,y in train_loader:\n",
    "    print(1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8b724fcba8>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b7250e048>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import *\n",
    "#plot(test_losses)\n",
    "plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1905952183895265, 2.015892108827999, 2.1310329382230258, 1.985882694335215, 1.869807677373881, 2.0913640778798404, 1.8503065948773267, 1.8877538291063125, 1.91443641541185, 1.8642055634985335, 1.834878183546482, 1.8328302411881279, 1.8374393558184703, 1.8579446916635585, 1.813999224414247, 1.832174593801553, 1.7899169059446847, 1.7758304707768202, 1.7645058642879994, 1.802437238128288, 1.768574142407999, 1.748361498254433, 1.8272818627015033, 1.843679213261173, 1.7538028258403309, 1.8229466771288576, 1.845396094127975, 1.7719376356773455, 1.7637339035084334, 1.7670536966426296]\n"
     ]
    }
   ],
   "source": [
    "print(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Test loss 8.0000, Accuracy: 900.00%\n"
     ]
    }
   ],
   "source": [
    "epoch , test_loss, acc_score = 1,8, 9\n",
    "print(f'Epoch {epoch}, Test loss {test_loss:.4f}, Accuracy: {100*acc_score:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-32af9c0c3221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbalanced_acc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbalanced_acc_score\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "acc_score = accuracy_score(y_true, y_pred)\n",
    "balanced_acc_score = balanced_accuracy_score(y_true, y_pred)\n",
    "print(acc_score,balanced_acc_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_name : str, data : List[torch.tensor], epochs : int, C : int, T : int, M : int, batch_size : int, n_train : int, \n",
    "         n_test: int , s_weights : List[float], pos : int, neg : int, lr : float = 1e-3 ):\n",
    "    #define ssl model\n",
    "    X_train = data[0]\n",
    "    X_test = data[1]\n",
    "    ssl_model = Relative_Positioning(StagerNet,C , T, embedding_dim = M )\n",
    "    ssl_model.to(float)\n",
    "    # datasets\n",
    "    train_dataset =  RP_Dataset(X_train, sampling_params = (pos, neg), temp_len = T ,\n",
    "                                n_features = C )\n",
    "    test_dataset =  RP_Dataset(X_test, sampling_params = (pos, neg), temp_len = T ,\n",
    "                                n_features = C )\n",
    "\n",
    "    train_sampler = WeightedSampler(train_dataset, batch_size = batch_size ,size = n_train,  \n",
    "                              weights = s_weights)\n",
    "    test_sampler = WeightedSampler(test_dataset, batch_size = batch_size ,size = n_test,  \n",
    "                              weights = s_weights)\n",
    "    samplers = {\"train\" : train_sampler, \"val\": test_sampler}\n",
    "\n",
    "\n",
    "    #train ssl \n",
    "    train_losses, test_losses, model = train_ssl(ssl_model, train_dataset, test_dataset,\n",
    "                                                 samplers,n_epochs=epochs, lr=lr,batch_size= batch_size, \n",
    "                                                 load_last_saved_model=False, num_workers= 0)\n",
    "\n",
    "    return train_losses, test_losses, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
