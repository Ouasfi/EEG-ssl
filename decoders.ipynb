{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from '/home/brain/EEG-ssl/dataset.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from settings  import *\n",
    "from preprocessing import *\n",
    "from models import Relative_Positioning, StagerNet\n",
    "import mne\n",
    "import dataset as ds\n",
    "from train import *\n",
    "import decode as dec\n",
    "from importlib import reload\n",
    "import process \n",
    "import preprocessing as pr\n",
    "reload(process)\n",
    "reload(dec)\n",
    "reload(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models params\n",
    "C = 64\n",
    "T =1000\n",
    "M = 10\n",
    "#training paramms\n",
    "epochs = 20\n",
    "batch_size = 40\n",
    "lr = 1e-3\n",
    "resume = False\n",
    "#datasets params\n",
    "n_train = 4000\n",
    "n_test = 500\n",
    "#sampling params\n",
    "pos= 3000\n",
    "neg = 7000\n",
    "\n",
    "s_weights = [0.5, 1-0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import *\n",
    "from pylab import *\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch.nn.functional import soft_margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (feature_extractor): StagerNet(\n",
       "    (relu): ReLU()\n",
       "    (spatial_conv): Conv2d(1, 64, kernel_size=(64, 1), stride=(1, 1))\n",
       "    (temp_conv1): Conv2d(1, 16, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25))\n",
       "    (batch_norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (temp_conv2): Conv2d(16, 16, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25))\n",
       "    (batch_norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (maxPool): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)\n",
       "    (flatten): Flatten()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear_class): Linear(in_features=5120, out_features=10, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (linear2): Linear(in_features=20, out_features=12, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssl_model = Relative_Positioning(StagerNet,C , T, embedding_dim = M )\n",
    "ssl_model.load_state_dict(torch.load(os.path.join(ROOT, 'saved_models', 'ssl_model.pt')))\n",
    "model = ssl_model.feature_extractor\n",
    "subjects = SUBJECTS[:-2]\n",
    "    #split data\n",
    "val_subjects = [SUBJECTS[-2]]\n",
    "aggregator = torch.mean\n",
    "decoder = dec.Decoder(model, aggregator, C, T, embedding_dim=M, hidden_dim = 20)\n",
    "decoder.to(float).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSampler(torch.utils.data.sampler.Sampler):\n",
    "    r\"\"\"Sample des windows randomly\n",
    "    Arguments:\n",
    "    ---------\n",
    "        dataset (Dataset): dataset to sample from\n",
    "        size (int): The total number of sequences to sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,dataset, batch_size,size,  weights):\n",
    "    \n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.size = size\n",
    "        self.dataset = dataset\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "        self.n_subjects = len(self.dataset.subjects)\n",
    "\n",
    "    def __iter__(self):\n",
    "        num_batches = self.size// self.batch_size\n",
    "        n_subject_samples = self.batch_size //self.n_subjects\n",
    "        while num_batches > 0:\n",
    "            #sample a subject \n",
    "            batch_subjects = choice(self.dataset.subjects,replace = False, size =5)\n",
    "            for subject in  batch_subjects:# TODO sample subjects ?\n",
    "                sampled = 0\n",
    "                #for each subject sample `n_subject_samples`  couples (target class, trial)\n",
    "                while sampled < n_subject_samples:\n",
    "                    indice  = torch.multinomial(\n",
    "                self.weights, 1, replacement=True)\n",
    "                    trial = choice(self.dataset.trials)\n",
    "                    sampled += 1\n",
    "                    yield ( indice,trial, subject)\n",
    "                \n",
    "            num_batches -=1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.size)   \n",
    "\n",
    "class SequentialSampler(torch.utils.data.sampler.Sampler):\n",
    "    r\"\"\"sampler for validation iterate sequentialy on subjects \n",
    "    Arguments:\n",
    "    ---------\n",
    "        dataset (Dataset): dataset to sample from\n",
    "        size (int): The total number of sequences to sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,dataset, batch_size,size,  weights):\n",
    "    \n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.size = size\n",
    "        self.dataset = dataset\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "        self.n_subjects = len(self.dataset.subjects)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        num_batches = self.size// self.batch_size\n",
    "        n_subject_samples = self.batch_size //self.n_subjects\n",
    "        while num_batches > 0:\n",
    "            sampled = 0\n",
    "            while sampled < self.batch_size:   \n",
    "                for subject in self.dataset.subjects:# TODO sample subjects ?\n",
    "                    for indice in range(len(self.weights)):\n",
    "                        for trial in self.dataset.trials:                \n",
    "                                sampled += 1\n",
    "                                yield ( indice,trial, subject)\n",
    "                \n",
    "            num_batches -=1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.size)\n",
    "class  Decoder_Dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Classe dataset  pour les differents sampling\n",
    "    '''\n",
    "    def __init__(self, subjects, trials, T , step, condition = 1):\n",
    "\n",
    "        self.subjects = subjects\n",
    "        self.temp_len = T\n",
    "        self.step = step\n",
    "        self.trials = trials\n",
    "        self.condition = condition\n",
    "    def load_epoch(self, index):\n",
    "        #print(index)\n",
    "        ( indice,trial, subject) = index\n",
    "        stim_id = STIMULUS_IDS[indice]\n",
    "        \n",
    "        epochs_path = os.path.join(RAW_DIR, f\"{subject}-epochs_{stim_id}_{self.condition}-epo.fif\")\n",
    "        if subject in recording_with_mastoid_channels:\n",
    "            epochs = mne.read_epochs(epochs_path, verbose = False)[trial].get_data()\n",
    "        else :\n",
    "            epochs = mne.read_epochs(epochs_path, verbose = False)[trial].drop_channels(['EXG5','EXG6']).get_data()\n",
    "\n",
    "        return epochs\n",
    "    def __getitem__(self, index):\n",
    "        classe = STIMULUS_IDS[index[0]]\n",
    "        sampled = self.load_epoch(index)\n",
    "        x_sample = torch.tensor(sampled).to(DEVICE).unfold(-1, self.temp_len, self.step ).permute(2,0,1,3)\n",
    "        return x_sample, index[0]\n",
    "    def __len__(self): len(self.subjects)*len(self.trials )*12\n",
    "        \n",
    "def collate(batch):\n",
    "   \n",
    "    samples= [item[0] for item in batch]\n",
    "    \n",
    "    targets = [item[1] for item in batch]\n",
    "    \n",
    "    return samples, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os\n",
    "from settings  import *\n",
    "from preprocessing import *\n",
    "from models import Relative_Positioning, StagerNet, Decoder\n",
    "from dataset import Decoder_Dataset, DecoderSampler\n",
    "import process\n",
    "from train import load_losses, save_losses\n",
    "from torch import nn, optim\n",
    "import argparse \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decoder(model, train_dataset, val_dataset,samplers, n_epochs=20, lr=1e-3, batch_size=256, load_last_saved_model=False, num_workers=8):\n",
    "\t\n",
    "\t\n",
    "\tif load_last_saved_model:\n",
    "\t\tmodel.load_state_dict(torch.load(os.path.join(ROOT, SAVED_MODEL_DIR, 'decoder.pt')))\n",
    "\n",
    "\tif torch.cuda.device_count() > 1:\n",
    "\t\tmodel = nn.DataParallel(model)\n",
    "        \n",
    "\tmodel.to(DEVICE)\n",
    "    \n",
    "   \n",
    "\n",
    "\ttrain_loader = train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size, num_workers=0,\n",
    "                                          sampler = samplers[\"train\"], collate_fn = collate)\n",
    "\tval_loader = val_loader = torch.utils.data.DataLoader(val_dataset, num_workers=0,\n",
    "                                          sampler = samplers[\"val\"])\n",
    "\tnew_train_losses, new_test_losses = _train_epochs_dec(model, train_loader, test_loader, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t dict(epochs=n_epochs, lr=lr))\n",
    "\n",
    "\tif load_last_saved_model:\n",
    "\t\ttrain_losses, test_losses = load_losses(SAVED_MODEL_DIR, 'decoder')\n",
    "\telse:\n",
    "\t\ttrain_losses = []\n",
    "\t\ttest_losses = []\n",
    "\t\n",
    "\ttrain_losses.extend(new_train_losses)\n",
    "\ttest_losses.extend(new_test_losses)\n",
    "\n",
    "\tsave_losses(train_losses, test_losses, SAVED_MODEL_DIR, 'decoder')\n",
    "\n",
    "\treturn train_losses, test_losses, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.248205721014568"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _train_dec(model, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    batch_size = train_loader.batch_size\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        print(batch_y)\n",
    "        print('in')\n",
    "        loss = 0\n",
    "        for x,y in zip(batch_x, batch_y):\n",
    "            x = x.squeeze(dim= 0 )\n",
    "            y = y.to(DEVICE)\n",
    "            out = model(x)\n",
    "            #print(out.shape)\n",
    "            loss = loss+ model.loss_fn(out.unsqueeze(dim =0), y)\n",
    "        loss =loss/batch_size\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    return mean(train_losses)\n",
    "def _eval_loss_dec(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.squeeze(dim= 0 )\n",
    "            y = y.to(DEVICE)\n",
    "            loss = model.loss_fn(model(x).unsqueeze(dim = 0), y)\n",
    "            total_loss += loss #* x[0].shape[0] #\n",
    "        avg_loss = total_loss / data_loader.sampler.size# / len(data_loader.dataset)\n",
    "    return avg_loss.item()\n",
    "\n",
    "def _train_epochs_dec(model, train_loader, test_loader, train_args):\n",
    "\tepochs, lr = train_args['epochs'], train_args['lr']\n",
    "\toptimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\tif not os.path.exists(SAVED_MODEL_DIR):\n",
    "\t\tos.makedirs(SAVED_MODEL_DIR)\n",
    "\t\n",
    "\ttrain_losses = []\n",
    "\ttest_losses = [_eval_loss_dec(model, test_loader)]\n",
    "\tfor epoch in range(1, epochs+1):\n",
    "\t\tmodel.train()\n",
    "\t\ttrain_losses.extend(_train_dec(model, train_loader, optimizer, epoch))\n",
    "\t\ttest_loss = _eval_loss_dec(model, test_loader)\n",
    "\t\ttest_losses.append(test_loss)\n",
    "        y_true, y_pred = get_test_results(model, test_loader)\n",
    "        \n",
    "\t\tprint(f'Epoch {epoch}, Test loss {test_loss:.4f}, \\tAccuracy: {100*acc_score:.2f}%')\n",
    "\t\t\n",
    "\t\t# save model every 10 epochs\n",
    "\t\tif epoch % 2 == 0:\n",
    "\t\t\ttorch.save(model.state_dict(), os.path.join(ROOT, 'saved_models', 'decoder_epoch{}.pt'.format(epoch)))\n",
    "\ttorch.save(model.state_dict(), os.path.join(ROOT, 'saved_models', 'decoder.pt'))\n",
    "\treturn train_losses, test_losses\n",
    "\n",
    "train_dataset = Decoder_Dataset(subjects,[0,1,2], T, step = 512)\n",
    "val_dataset = Decoder_Dataset(subjects,[3,4], T, step = 512)\n",
    "train_sampler = DecoderSampler(train_dataset, batch_size = 21, weights = [1/12]*12, size = 65)\n",
    "val_sampler = SequentialSampler(val_dataset, batch_size = 60, weights = [1/12]*12, size = 65)\n",
    "samplers = {\"train\" : train_sampler, \"val\": val_sampler}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = 21, num_workers=0,\n",
    "                                          sampler = samplers[\"train\"], collate_fn = collate)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, num_workers=0,\n",
    "                                          sampler = samplers[\"val\"])\n",
    "#for x ,y in train_loader:\n",
    "    #print(y)\n",
    "optimizer = optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "#train_losses = _train_dec(decoder, train_loader,optimizer, 2 )\n",
    "_eval_loss_dec(decoder, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.084803566683392"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "[tensor([5]), tensor([10]), tensor([0]), tensor([1]), tensor([11]), tensor([5]), tensor([5]), tensor([2])]\n"
     ]
    }
   ],
   "source": [
    "train_sampler = DecoderSampler(train_dataset, batch_size = 15, weights = [1/12]*12, size = 65)\n",
    "val_sampler = SequentialSampler(val_dataset, batch_size = 60, weights = [1/12]*12, size = 65)\n",
    "samplers = {\"train\" : train_sampler, \"val\": val_sampler}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = 15, num_workers=0,\n",
    "                                          sampler = samplers[\"train\"], collate_fn = collate)\n",
    "for x ,y in train_loader:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 66>\n",
      "Performance of the network on the test trials:\n",
      "\tAccuracy: 8.33%\n",
      "\tBalanced accuracy: 8.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08333333333333333, 0.08333333333333333)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import get_results as res\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "def get_test_results(model, test_loader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for x, y in test_loader:\n",
    "            \n",
    "            x = x.to(DEVICE).to(float).contiguous().squeeze(dim= 0)\n",
    "            #x = x.reshape(-1,1,x.shape[2], 1000)\n",
    "            y = y.to(DEVICE).to(float).contiguous()\n",
    "            out = model(x)\n",
    "            _, predicted = torch.max(softmax(out.unsqueeze(dim =0)), 1)\n",
    "            y_true.extend(list(y.cpu().numpy()))\n",
    "            y_pred.extend(list(predicted.cpu().numpy()))\n",
    "    return y_true, y_pred\n",
    "\n",
    "def decoder_scores(model, subjects, trials):\n",
    "    \n",
    "    test_dataset = Decoder_Dataset(subjects,trials, T, step = 512)\n",
    "    test_sampler = SequentialSampler(test_dataset, batch_size = 60, weights = [1/12]*12, size = 65)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, num_workers=0,\n",
    "                                          sampler = test_sampler)\n",
    "    y_true, y_pred = get_test_results(model, test_loader)\n",
    "    acc_score = accuracy_score(y_true, y_pred)\n",
    "    balanced_acc_score = balanced_accuracy_score(y_true, y_pred)\n",
    "    print(f'Performance of the network on the test trials:')\n",
    "    print(f'\\tAccuracy: {100*acc_score:.2f}%')\n",
    "    print(f'\\tBalanced accuracy: {100*balanced_acc_score:.2f}%')\n",
    "    return acc_score, balanced_acc_score\n",
    "\n",
    "decoder_scores(decoder, subjects, [3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09523809523809523 0.09523809523809523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "acc_score = accuracy_score(y_true, y_pred)\n",
    "balanced_acc_score = balanced_accuracy_score(y_true, y_pred)\n",
    "print(acc_score,balanced_acc_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/brain/openmiir/raw_data/P01-raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64)  idle\n",
      "    Range : 0 ... 2478165 =      0.000 ...  4840.166 secs\n",
      "Ready.\n",
      "Reading 0 ... 2478165  =      0.000 ...  4840.166 secs...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ds.Decoder_Dataset(subjects,[0,1,2], T, step = 512)\n",
    "val_dataset = ds.Decoder_Dataset(subjects,[3,4], T, step = 512)\n",
    "train_sampler = ds.DecoderSampler(train_dataset, batch_size = 12, weights = [1/12]*12, size = 65)\n",
    "val_sampler = ds.DecoderSampler(val_dataset, batch_size = 12, weights = [1/12]*12, size = 65)\n",
    "samplers = {\"train\" : train_sampler, \"val\": test_sampler}\n",
    "trainloader = torch.utils.data.DataLoader(dataset, num_workers=0,sampler = samplers[\"train\"])\n",
    "train_losses, test_losses, model = train_decoder(decoder, dataset,val_dataset,sampler, n_epochs=epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Test loss 0.0003\n",
      "Epoch 2, Test loss 0.0003\n",
      "Epoch 3, Test loss 0.0003\n",
      "Epoch 4, Test loss 0.0002\n",
      "Epoch 5, Test loss 0.0002\n",
      "Epoch 6, Test loss 0.0002\n",
      "Epoch 7, Test loss 0.0002\n",
      "Epoch 8, Test loss 0.0002\n",
      "Epoch 9, Test loss 0.0002\n",
      "Epoch 10, Test loss 0.0002\n",
      "Epoch 11, Test loss 0.0002\n",
      "Epoch 12, Test loss 0.0002\n",
      "Epoch 13, Test loss 0.0002\n",
      "Epoch 14, Test loss 0.0002\n",
      "Epoch 15, Test loss 0.0002\n",
      "Epoch 16, Test loss 0.0002\n",
      "Epoch 17, Test loss 0.0002\n",
      "Epoch 18, Test loss 0.0002\n",
      "Epoch 19, Test loss 0.0002\n",
      "Epoch 20, Test loss 0.0002\n"
     ]
    }
   ],
   "source": [
    "def main(model_name : str, data : List[torch.tensor], epochs : int, C : int, T : int, M : int, batch_size : int, n_train : int, \n",
    "         n_test: int , s_weights : List[float], pos : int, neg : int, lr : float = 1e-3 ):\n",
    "    #define ssl model\n",
    "    X_train = data[0]\n",
    "    X_test = data[1]\n",
    "    ssl_model = Relative_Positioning(StagerNet,C , T, embedding_dim = M )\n",
    "    ssl_model.to(float)\n",
    "    # datasets\n",
    "    train_dataset =  RP_Dataset(X_train, sampling_params = (pos, neg), temp_len = T ,\n",
    "                                n_features = C )\n",
    "    test_dataset =  RP_Dataset(X_test, sampling_params = (pos, neg), temp_len = T ,\n",
    "                                n_features = C )\n",
    "\n",
    "    train_sampler = WeightedSampler(train_dataset, batch_size = batch_size ,size = n_train,  \n",
    "                              weights = s_weights)\n",
    "    test_sampler = WeightedSampler(test_dataset, batch_size = batch_size ,size = n_test,  \n",
    "                              weights = s_weights)\n",
    "    samplers = {\"train\" : train_sampler, \"val\": test_sampler}\n",
    "\n",
    "\n",
    "    #train ssl \n",
    "    train_losses, test_losses, model = train_ssl(ssl_model, train_dataset, test_dataset,\n",
    "                                                 samplers,n_epochs=epochs, lr=lr,batch_size= batch_size, \n",
    "                                                 load_last_saved_model=False, num_workers= 0)\n",
    "\n",
    "    return train_losses, test_losses, model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
